{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ecd5121-6d11-4c6d-889f-c933368e6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql import SparkSession, DataFrame as SparkDataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col,isnan, when, count, coalesce\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, lag, lead\n",
    "import json\n",
    "from functools import reduce\n",
    "import sys\n",
    "from cassandra.cluster import Cluster\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import lag, col\n",
    "import mysql.connector as database\n",
    "import time\n",
    "import sqlalchemy\n",
    "\n",
    "# from mock.tasks import adiciona_carro}\n",
    "cluster = Cluster(['cassandra'])\n",
    "session = cluster.connect()\n",
    "\n",
    "ss = SparkSession.builder \\\n",
    "           .appName('SparkByExamples') \\\n",
    "           .config(\"spark.jars\", \"/usr/share/java/mariadb-java-client.jar\") \\\n",
    "           .getOrCreate()\n",
    "sql = SQLContext(ss)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "session.execute(\"USE simulacao\")\n",
    "\n",
    "params = json.load(open('./mock/parametros.json'))\n",
    "\n",
    "connection = database.connect(\n",
    "    host=\"host.docker.internal\",\n",
    "    port=3306,\n",
    "    user=\"root\",\n",
    "    password=\"secret\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor(buffered=True)\n",
    "cursor.execute(\"USE dashboard;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8997ea28-71c1-4382-b793-4c286f511bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualiza_media(media_atual, tamanho_atual, media_add, tamanho_add):\n",
    "    if media_add == None:\n",
    "        return media_atual\n",
    "    if tamanho_atual == 0:\n",
    "        return media_add\n",
    "    tamanho_total = tamanho_atual + tamanho_add\n",
    "    return (media_atual/tamanho_total)*tamanho_atual + (media_add/tamanho_total)*tamanho_add\n",
    "\n",
    "def processa_velocidade_media(batch):\n",
    "    global vel_media, n_vel_media\n",
    "    batch = batch.filter(F.col(\"vel_y\").isNotNull())\n",
    "    \n",
    "    # group by \"rodovia\" and aggregate the mean of \"velocidade\"\n",
    "    mean_df = batch.groupBy(\"rodovia\").agg(F.mean(F.abs(\"vel_y\").alias('vel_y')).alias('vel_y'))\n",
    "    # collect the rows as a list\n",
    "    mean_rows = mean_df.collect()\n",
    "    # create a dictionary with \"rodovia\" as key and mean as value\n",
    "    mean_dict = {row.asDict()[\"rodovia\"]: row.asDict()[\"vel_y\"] for row in mean_rows}\n",
    "    # group by \"rodovia\" and aggregate the mean of \"velocidade\"\n",
    "    length_df = batch.groupBy(\"rodovia\").agg(F.count(\"vel_y\"))\n",
    "    length_df = length_df.withColumnRenamed(\"count(vel_y)\", \"vel_y\")\n",
    "    # collect the rows as a list\n",
    "    length_rows = length_df.collect()\n",
    "    # create a dictionary with \"rodovia\" as key and mean as value\n",
    "    length_dict = {row.asDict()[\"rodovia\"]: row.asDict()[\"vel_y\"] for row in length_rows}\n",
    "    for key in length_dict.keys():\n",
    "        n_vel_media[key]+=length_dict[key]\n",
    "        vel_media[key] = atualiza_media(vel_media[key], n_vel_media[key], mean_dict[key], length_dict[key])\n",
    "\n",
    "def processa_tempo_cruzamento(batch):\n",
    "    global n_tempo_medio, tempo_medio\n",
    "    batch = batch.filter(F.col(\"tempo_cruzamento\").isNotNull())\n",
    "    # group by \"rodovia\" and aggregate the mean of \"velocidade\"\n",
    "    batch.show()\n",
    "    mean_df = batch.groupBy(\"rodovia\").agg(F.mean(\"tempo_cruzamento\"))\n",
    "    mean_df = mean_df.withColumnRenamed(\"avg(tempo_cruzamento)\", \"tempo_cruzamento\")\n",
    "    # collect the rows as a list\n",
    "    mean_rows = mean_df.collect()\n",
    "    # create a dictionary with \"rodovia\" as key and mean as value\n",
    "    mean_dict = {row.asDict()[\"rodovia\"]: row.asDict()[\"tempo_cruzamento\"] for row in mean_rows}\n",
    "\n",
    "    # group by \"rodovia\" and aggregate the mean of \"velocidade\"\n",
    "    length_df = batch.groupBy(\"rodovia\").agg(F.count(\"tempo_cruzamento\"))\n",
    "    length_df = length_df.withColumnRenamed(\"count(tempo_cruzamento)\", \"tempo_cruzamento\")\n",
    "    # collect the rows as a list\n",
    "    length_rows = length_df.collect()\n",
    "    # create a dictionary with \"rodovia\" as key and mean as value\n",
    "    length_dict = {row.asDict()[\"rodovia\"]: row.asDict()[\"tempo_cruzamento\"] for row in length_rows}\n",
    "    for key in length_dict.keys():\n",
    "        n_tempo_medio[key] += length_dict[key]\n",
    "        tempo_medio[key] = atualiza_media(tempo_medio[key], n_tempo_medio[key], mean_dict[key], length_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c1d527-0e4f-4ec7-bd26-ba5443082744",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "last = 0\n",
    "i = 0\n",
    "p = [[key]+list(params[key].values()) for key in params.keys()]\n",
    "p = ss.createDataFrame(p, [\"Rodovia\"]+list(params[list(params.keys())[0]].keys()))\n",
    "\n",
    "T = 10000\n",
    "\n",
    "schema = StructType([\n",
    "  StructField('placa', StringType(), True),\n",
    "  StructField('total_multas', IntegerType(), True),\n",
    "  StructField('tempo_da_simulacao', IntegerType(), True),\n",
    "  StructField('proibidoCircular', IntegerType(), True)\n",
    "])\n",
    "\n",
    "df_multas = ss.createDataFrame([], schema)\n",
    "\n",
    "schema2 = StructType([\n",
    "  StructField('placa', StringType(), True),\n",
    "  StructField('total_perigosa', IntegerType(), True),\n",
    "  StructField('tempo_da_simulacao', IntegerType(), True),\n",
    "  StructField('perigosa?', IntegerType(), True),\n",
    "  StructField('tempo_da_simulacao_intervalo',IntegerType(),True)\n",
    "])\n",
    "\n",
    "df_perigosa = ss.createDataFrame([], schema2)\n",
    "\n",
    "Velocidades_Maximas = p.select(F.col('rodovia'), F.col(\"VelocidadeMaxima\"))\n",
    "Aceleracoes_Maximas = p.select(F.col('rodovia'), 0.8*F.col(\"AceleracaoMaxima\"))\n",
    "Aceleracoes_Maximas = Aceleracoes_Maximas.withColumnRenamed(\"(AceleracaoMaxima * 0.8)\", \"AceleracaoMaxima\")\n",
    "\n",
    "rodovias = p.select(F.collect_list('rodovia')).collect()[0][0]\n",
    "vel_media = {rodovia:0 for rodovia in rodovias} #\"BR-116\": 0, \"BR-040\": 0, \"BR-135\": 0, \"BR-393\": 0}\n",
    "n_vel_media = {rodovia:0 for rodovia in rodovias} # {\"BR-116\": 0, \"BR-040\": 0, \"BR-135\": 0, \"BR-393\": 0}\n",
    "\n",
    "tempo_medio = {rodovia:0 for rodovia in rodovias}\n",
    "n_tempo_medio = {rodovia:0 for rodovia in rodovias}\n",
    "\n",
    "def atualiza_media(media_atual, tamanho_atual, media_add, tamanho_add):\n",
    "    if media_add == None:\n",
    "        return media_atual\n",
    "    if tamanho_atual == 0:\n",
    "        return media_add\n",
    "    tamanho_total = tamanho_atual + tamanho_add\n",
    "    return (media_atual/tamanho_total)*tamanho_atual + (media_add/tamanho_total)*tamanho_add\n",
    "\n",
    "def multas(batch):\n",
    "    global df_multas, T\n",
    "    # Criar uma janela que particiona por placa e ordene por tempo_da_simulacao\n",
    "    window = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "    \n",
    "    # Calcular a soma cumulativa de multas por carro na janela\n",
    "    batch = batch.withColumn('multado',F.col('multado').cast('int'))\n",
    "    batch = batch.withColumn(\"total_multas\", F.sum(\"multado\").over(window))\n",
    "    batch = batch.withColumn('proibidoCircular', F.lit(0))\n",
    "\n",
    "    window2 = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "\n",
    "    df = batch.filter(F.col('multado')==1).select('placa','total_multas','tempo_da_simulacao','proibidoCircular')\n",
    "\n",
    "    df = df_multas.union(df)\n",
    "    # Calcular o número de linha por carro na janela\n",
    "    df = df.withColumn(\"num_linha\", F.row_number().over(window2))\n",
    "\n",
    "    df = df.withColumn(\"primeiro_tempo\", F.first(\"tempo_da_simulacao\").over(window))\n",
    "    df = df.withColumn(\"ultimo_tempo\", F.last(\"tempo_da_simulacao\").over(window))\n",
    "    df = df.withColumn('proibidoCircular',F.when(((F.col('ultimo_tempo')-F.col('primeiro_tempo')) < T) & (F.col('total_multas')>10),1).otherwise(0))\n",
    "    \n",
    "    # Filtrar as linhas que tenham o número de linha menor ou igual a 10\n",
    "    df_multas = df.filter(df.num_linha <= 10).select('placa','total_multas','tempo_da_simulacao','proibidoCircular')\n",
    "\n",
    "T_perigosa = 200\n",
    "N_eventos = 3\n",
    "I_perigosa = 1000\n",
    "\n",
    "def perigosas(batch):\n",
    "    global df_perigosa, T_perigosa, N_eventos,I_perigosa\n",
    "    batch = batch.withColumn('perigosa_quant',F.col('acima_vel').cast('int') + F.col('acima_acel').cast('int') + F.col('troca_faixa').cast('int'))\n",
    "    # Criar uma janela que particiona por placa e ordene por tempo_da_simulacao\n",
    "    window = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "    \n",
    "    # Calcular a soma cumulativa de multas por carro na janela\n",
    "    batch = batch.withColumn(\"total_perigosa\", F.sum(\"perigosa_quant\").over(window))\n",
    "    batch = batch.withColumn('perigosa?', F.lit(0))\n",
    "    batch = batch.withColumn('tempo_da_simulacao_intervalo',F.lit(I_perigosa))\n",
    "\n",
    "    window2 = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "\n",
    "    df = batch.filter(F.col('perigosa_quant')>=1).select('placa','total_perigosa','tempo_da_simulacao','perigosa?','tempo_da_simulacao_intervalo')\n",
    "\n",
    "    df = df_perigosa.union(df)\n",
    "    # Calcular o número de linha por carro na janela\n",
    "    df = df.withColumn(\"num_linha\", F.row_number().over(window2))\n",
    "\n",
    "    df = df.withColumn(\"primeiro_tempo\", F.first(\"tempo_da_simulacao\").over(window))\n",
    "    df = df.withColumn(\"ultimo_tempo\", F.last(\"tempo_da_simulacao\").over(window))\n",
    "    df = df.withColumn('perigosa?',F.when(((F.col('ultimo_tempo')-F.col('primeiro_tempo')) < I_perigosa) & (F.col('total_perigosa')>N_eventos),1).otherwise(0))\n",
    "    df = df.withColumn('tempo_da_simulacao_intervalo',F.col('tempo_da_simulacao_intervalo')+F.col('tempo_da_simulacao'))\n",
    "    \n",
    "    # Filtrar as linhas que tenham o número de linha menor ou igual a N\n",
    "    df_perigosa = df.filter(df.num_linha <= N_eventos).select('placa','total_perigosa','tempo_da_simulacao','perigosa?','tempo_da_simulacao_intervalo')\n",
    "    \n",
    "collision_tolerance = 1\n",
    "collision_tolerance_quad = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b391d3-08e7-44d6-8746-1d1f64671785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVelMedia(df2):\n",
    "    df2['vel_media'] = df2['rodovia'].map(vel_media)\n",
    "    return df2\n",
    "\n",
    "def getTempoMedia(df2):\n",
    "    df2['tempo_medio'] = df2['rodovia'].map(tempo_medio)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40eab59d-bf12-4b37-af20-fe3c15e81037",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2000\n",
    "c = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a527b20f-a1c2-4c50-bb91-d5f4a3e8474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Aggregation query used without partition key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de extração do banco: 1.3160288333892822\n",
      "+-------+-------+------------+-----------+----------------+\n",
      "|rodovia|  placa|tempo_inicio|tempo_final|tempo_cruzamento|\n",
      "+-------+-------+------------+-----------+----------------+\n",
      "| BR-262|ARG1B12|        null|        480|           -2195|\n",
      "| BR-262|ARG1B12|        null|        583|              30|\n",
      "| BR-262|ARG1B12|         651|        651|              12|\n",
      "| BR-262|ARG1B12|        null|        672|              21|\n",
      "| BR-262|ARG1B12|         738|        738|              20|\n",
      "| BR-262|ARG1B12|         751|        751|              13|\n",
      "| BR-262|ARG1B12|         759|        759|               8|\n",
      "| BR-262|ARG1B12|         778|        778|              19|\n",
      "| BR-262|ARG1B12|        null|        837|              59|\n",
      "| BR-262|ARG1B12|        null|       1002|              81|\n",
      "| BR-262|ARG1B12|        null|       1068|              41|\n",
      "| BR-262|ARG1B12|        null|       1154|              30|\n",
      "| BR-262|ARG1B12|        1188|       1188|               7|\n",
      "| BR-262|ARG1B12|        1229|       1229|              41|\n",
      "| BR-262|ARG1B12|        null|       1312|              83|\n",
      "| BR-262|ARG1B12|        null|       2135|             561|\n",
      "| BR-262|ARG1B12|        null|       2564|             235|\n",
      "| BR-060|ARG1B23|        null|        538|            -661|\n",
      "| BR-060|ARG1B23|         575|        575|              17|\n",
      "| BR-060|ARG1B23|        null|        590|              15|\n",
      "+-------+-------+------------+-----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 102\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# df = df.join(df_multas,on=['placa','tempo_da_simulacao'],how='left')\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m## CALCULO DA RODOVIA ##\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Obter o valor máximo da coluna tempo_da_simulacao\u001b[39;00m\n\u001b[1;32m    101\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrodovia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtempo_da_simulacao\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m max_tempo \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtempo_da_simulacao\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Filtrar o dataframe pelo valor máximo\u001b[39;00m\n\u001b[1;32m    106\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mfilter(df2\u001b[38;5;241m.\u001b[39mtempo_da_simulacao \u001b[38;5;241m==\u001b[39m max_tempo)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 42118)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "       ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_cruzamento = ss.createDataFrame([], \"rodovia: string, placa: string, tempo_inicio: bigint, tempo_final: bigint,tempo_cruzamento: bigint\")\n",
    "while i < True:\n",
    "    start_time2 = time.time()\n",
    "    st=time.time()\n",
    "    query = f\"SELECT MAX(tempo_da_simulacao) FROM simulacao;\"\n",
    "    max = list(session.execute(query))[0][0]\n",
    "\n",
    "    if b > max:\n",
    "        b = max\n",
    "        a = max - c\n",
    "    if a < 1:\n",
    "        a = 1\n",
    "    \n",
    "    query = f\"SELECT * FROM simulacao WHERE tempo_da_simulacao >= {a} AND tempo_da_simulacao <= {b} ALLOW FILTERING;\"\n",
    "    r = list(session.execute(query))\n",
    "    \n",
    "    et=time.time()\n",
    "    \n",
    "    if r != []:\n",
    "        print(\"GO!\")\n",
    "        i+=1\n",
    "        \n",
    "        st=time.time()\n",
    "        \n",
    "        df = ss.createDataFrame(r)\n",
    "        \n",
    "        windowSpec = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "        \n",
    "        df = df.withColumn(\"prev_pos_y\", lag(\"pos_y\", 1).over(windowSpec))\n",
    "        df = df.withColumn(\"prev_tempo_da_simulacao\", lag(\"tempo_da_simulacao\", 1).over(windowSpec))\n",
    "        df = df.withColumn(\"vel_y\", (col(\"pos_y\") - col(\"prev_pos_y\")) / (col(\"tempo_da_simulacao\") - col(\"prev_tempo_da_simulacao\")))\n",
    "        df = df.withColumn(\"prev_vel_y\", lag(\"vel_y\", 1).over(windowSpec))\n",
    "        df = df.withColumn(\"acel_y\", (col(\"vel_y\") - col(\"prev_vel_y\")) / (col(\"tempo_da_simulacao\") - col(\"prev_tempo_da_simulacao\")))\n",
    "        \n",
    "        df = df.withColumn(\"posicao_prevista\", col(\"pos_y\") + col(\"vel_y\") * (collision_tolerance) + col(\"acel_y\") * collision_tolerance_quad)\n",
    "        \n",
    "        window_spec_rf = Window.partitionBy(\"rodovia\", \"pos_x\").orderBy('pos_y')\n",
    "        lag_column = col(\"posicao_prevista\") - lag(col(\"posicao_prevista\")).over(window_spec_rf)\n",
    "        lead_column = lead(col(\"posicao_prevista\")).over(window_spec_rf) - col(\"posicao_prevista\")\n",
    "        \n",
    "        # Add the lag column to the DataFrame\n",
    "        df = df.withColumn(\"Risco_Colisão\", when(((lag_column < 0) & (col(\"rodovia\") == lag(col(\"rodovia\")).over(window_spec_rf)) & (col(\"pos_x\") == lag(col(\"pos_x\")).over(window_spec_rf)))| ((lead_column < 0) & (col(\"rodovia\") == lead(col(\"rodovia\")).over(window_spec_rf)) & (col(\"pos_x\") == lead(col(\"pos_x\")).over(window_spec_rf))), 1).otherwise(0))\n",
    "\n",
    "        processa_velocidade_media(df)\n",
    "        \n",
    "        df = df.join(Velocidades_Maximas,on='rodovia',how='left')\n",
    "        df = df.join(Aceleracoes_Maximas,on='rodovia',how='left')\n",
    "        \n",
    "        df = df.withColumn('acima_vel',F.abs(col('vel_y'))>F.abs(col('VelocidadeMaxima')))\n",
    "        df = df.withColumn('acima_acel',F.abs(col('acel_y'))>F.abs(col('AceleracaoMaxima')))\n",
    "        \n",
    "        df = df.withColumn(\"troca_faixa\", col(\"pos_x\") != lag(\"pos_x\", 1).over(windowSpec))\n",
    "        \n",
    "        # contador de trocas\n",
    "        \n",
    "        df = df.withColumn('multado',((F.col('acima_vel') == 1) & (lag('acima_vel').over(windowSpec) == 0)))\n",
    "        df = df.withColumn(\"on_road\", (((col(\"pos_y\") > 0) & (col('pos_y') < 800))))\n",
    "        \n",
    "        df = df.withColumn('tempo_inicio',when(((F.col('on_road') == True) & (lag('on_road').over(windowSpec) == False)), F.col(\"tempo_da_simulacao\")).otherwise(None))\n",
    "        df = df.withColumn('tempo_final',when(((F.col('on_road') == True) & (lead('on_road').over(windowSpec) == False)), F.col(\"tempo_da_simulacao\")).otherwise(None))\n",
    "        df = df.withColumn('tempo_cruzamento',F.lit(None))\n",
    "        df_cruzamento = df_cruzamento.union(df.select('rodovia', 'placa', 'tempo_inicio','tempo_final','tempo_cruzamento').filter((F.col('vel_y') != 0) & (F.col('tempo_inicio').isNotNull() | F.col('tempo_final').isNotNull())))\n",
    "        windowSpec2 = Window.partitionBy('placa','rodovia').orderBy('tempo_final')\n",
    "        \n",
    "        df_cruzamento = df_cruzamento.withColumn('tempo_cruzamento', col('tempo_final') - lag('tempo_inicio').over(windowSpec2))\n",
    "        \n",
    "        processa_tempo_cruzamento(df_cruzamento)\n",
    "        df_cruzamento = df_cruzamento.filter(df_cruzamento.tempo_cruzamento.isNull())\n",
    "        df = df.withColumn('time_on_road',F.lit(0))\n",
    "        \n",
    "        windowSpec = Window.partitionBy(\"placa\",'rodovia').orderBy('tempo_da_simulacao')\n",
    "        \n",
    "        df = df.withColumn(\"prev_pos_y\", lag(\"pos_y\", 1).over(windowSpec))\n",
    "        windowSpec = Window.partitionBy('rodovia',\"placa\").orderBy('tempo_da_simulacao')\n",
    "        \n",
    "        df = df.withColumn(\"prev_pos_y\", lag(\"pos_y\", 1).over(windowSpec))\n",
    "\n",
    "        \n",
    "        multas(df)\n",
    "\n",
    "        perigosas(df)\n",
    "\n",
    "        window3 = Window.partitionBy(\"placa\").orderBy(\"tempo_da_simulacao\")\n",
    "\n",
    "        df = df.join(df_multas,on=['placa','tempo_da_simulacao'],how='left')\n",
    "\n",
    "\n",
    "        df = df.join(df_perigosa,on=['placa','tempo_da_simulacao'])\n",
    "\n",
    "        # Calcular o máximo da coluna proibidoCircular na janela\n",
    "        df = df.withColumn(\"proibidoCircular\", F.max(\"proibidoCircular\").over(window3))\n",
    "\n",
    "        df = df.withColumn(\"perigosa_I\", when(((lag(\"perigosa?\", 1).over(window3) == 1) & (F.col('tempo_da_simulacao') < F.col('tempo_da_simulacao_intervalo'))), 1).otherwise(0))\n",
    "        \n",
    "        # df = df.join(df_multas,on=['placa','tempo_da_simulacao'],how='left')\n",
    "        \n",
    "        ## CALCULO DA RODOVIA ##\n",
    "\n",
    "        # Obter o valor máximo da coluna tempo_da_simulacao\n",
    "        df2 = df.select('rodovia', 'tempo_da_simulacao')\n",
    "        max_tempo = df2.select(F.max(\"tempo_da_simulacao\")).collect()[0][0]\n",
    "\n",
    "        \n",
    "        # Filtrar o dataframe pelo valor máximo\n",
    "        df2 = df2.filter(df2.tempo_da_simulacao == max_tempo)\n",
    "\n",
    "        \n",
    "        # Aplicar um unique no dataframe df2\n",
    "        df2 = df2.distinct()\n",
    "        \n",
    "        max_tempo = df2.select(F.max(\"tempo_da_simulacao\")).collect()[0][0]\n",
    "        df2 = df2.filter(df2.tempo_da_simulacao == max_tempo)\n",
    "\n",
    "        \n",
    "        # Criar uma janela de tamanho 1 sobre a coluna rodovia\n",
    "        w = Window.partitionBy(F.col(\"rodovia\")).orderBy(F.col(\"rodovia\")).rangeBetween(0, 0)\n",
    "        \n",
    "        # Contar as placas distintas por rodovia\n",
    "        unique_placas = df.filter(df.tempo_da_simulacao == max_tempo)\\\n",
    "                          .withColumn(\"placa_distinct\", F.size(F.collect_set(\"placa\").over(w)))\\\n",
    "                          .select(\"rodovia\", \"placa_distinct\")\\\n",
    "                          .distinct()\n",
    "        \n",
    "        # Contar as placas distintas por rodovia que tiveram colisão\n",
    "        unique_colisao = df.filter((df.tempo_da_simulacao == max_tempo) & (df.vel_y == 0))\\\n",
    "                          .withColumn(\"placa_distinct_colissao\", F.size(F.collect_set(\"placa\").over(w)))\\\n",
    "                          .select(\"rodovia\", \"placa_distinct_colissao\")\\\n",
    "                          .distinct()\n",
    "\n",
    "        \n",
    "        df2 = df2.join(unique_placas,on='rodovia',how='left')\n",
    "        df2 = df2.join(unique_colisao,on='rodovia',how='left')\n",
    "\n",
    "        df2 = df2.fillna(0)\n",
    "        \n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time2\n",
    "        elapsed_time\n",
    "        \n",
    "        df2 = df2.withColumn('tempo_processamento', F.lit(elapsed_time))\n",
    "        df2 = df2.withColumn('tempo_processamento', F.lit(elapsed_time))\n",
    "        df2 = df2.withColumn('tempo_processamento', F.lit(elapsed_time))\n",
    "\n",
    "        \n",
    "        datap2 = df2.toPandas()\n",
    "\n",
    "        datap2 = getVelMedia(datap2)\n",
    "\n",
    "        datap2 = getTempoMedia(datap2)\n",
    "        \n",
    "        query2 = f\"\"\" REPLACE INTO rodovias (nome_rodovia,horario_registro,total_veiculos,veiculos_colisao,tempo_processamento,velocidade_media,tempo_medio_cruzamento)\n",
    "        \n",
    "                VALUES {','.join([str(i) for i in list(datap2.to_records(index=False))])};\n",
    "                        \n",
    "                \"\"\".replace(\"None\", \"NULL\").replace(\"\\n\", \"\").replace(\"nan\", \"NULL\")        \n",
    "            \n",
    "        data = df.select('placa','pos_x','pos_y','acel_y','vel_y', 'rodovia', 'tempo_da_simulacao',F.col('proibidoCircular'),'Risco_Colisão',F.col('troca_faixa'))#,'acima_vel')\n",
    "        datap = data.toPandas()\n",
    "\n",
    "\n",
    "        query = f\"\"\" REPLACE INTO carros (placa, pos_x, pos_y, aceleracao, velocidade, rodovia, horario_registro, multas, risco_colisao, direcao_perigosa)\n",
    "    \n",
    "                    VALUES {','.join([str(i) for i in list(datap.to_records(index=False))])};\n",
    "                    \n",
    "                    \"\"\".replace(\"None\", \"NULL\").replace(\"\\n\", \"\").replace(\"nan\", \"NULL\")\n",
    "    \n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        cursor.execute(query2)\n",
    "        connection.commit()\n",
    "\n",
    "    \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time2\n",
    "        # total = total + elapsed_time\n",
    "    \n",
    "        print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac74b46-ab62-4c5f-8767-56be9e4caaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BR-040': 1.933333333333334,\n",
       " 'BR-116': 1.6386363636363637,\n",
       " 'BR-135': 4.739583333333334,\n",
       " 'BR-393': 0,\n",
       " 'BR-101': 0,\n",
       " 'BR-376': 0,\n",
       " 'BR-262': -0.6904761904761909,\n",
       " 'BR-153': 0,\n",
       " 'BR-230': 0,\n",
       " 'BR-349': 0,\n",
       " 'BR-060': 0,\n",
       " 'BR-050': 0,\n",
       " 'BR-070': 3.3095238095238093,\n",
       " 'BR-163': 0,\n",
       " 'BR-277': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo_medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e3c5-e09b-42b8-85e7-c53055a14c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "datap['proibidoCircular'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0dce6-e49c-4f9c-9bd4-b940687ae407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multas.toPandas()['total_multas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0f3d4-697a-46f3-8f61-ad4657be6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "datap[datap['placa']=='PER1M12'][120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcd27a-17b7-4b30-9319-4fd8a8d0a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "datap2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
