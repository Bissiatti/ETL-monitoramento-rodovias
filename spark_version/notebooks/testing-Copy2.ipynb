{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92314900-b3b6-4ed7-86a9-a26474046fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql import SparkSession, DataFrame as SparkDataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col,isnan, when, count, coalesce\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import json\n",
    "from functools import reduce\n",
    "import sys\n",
    "from cassandra.cluster import Cluster\n",
    "import os\n",
    "# from mock.tasks import adiciona_carro\n",
    "cluster = Cluster(['cassandra'])\n",
    "session = cluster.connect()\n",
    "\n",
    "ss = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "sql = SQLContext(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ace41b7-0602-4d30-8fc2-4a41b884dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fc5f4823150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"USE simulacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99159133-eb27-440d-9e2f-24f9f9e3ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2851/795349805.py:1: DeprecationWarning: ResultSet indexing support will be removed in 4.0. Consider using ResultSet.one() to get a single row.\n",
      "  session.execute(\"select count(*) from simulacao\")[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(count=3071)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"select count(*) from simulacao\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160193c9-855e-4797-baf4-e9967e76c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.execute(\"SELECT * FROM simulacao WHERE tempo_da_simulacao = 142 ALLOW FILTERING;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849c8f85-bcf0-4f98-bc45-1bcda2f196d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2851/223460175.py:1: DeprecationWarning: ResultSet indexing support will be removed in 4.0. Consider using ResultSet.one() to get a single row.\n",
      "  result[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(placa='COL1R23', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=655.0, pos_y=868.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526f2e12-46d5-4b63-84af-fd66bba99e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac82b92-0f58-4fc1-ab9c-61a7b43475f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(placa='COL1R23', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=655.0, pos_y=868.0),\n",
       " Row(placa='CHI0G12', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=385.0, pos_y=198.05),\n",
       " Row(placa='CHI2E34', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=774.15),\n",
       " Row(placa='URU2Y34', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=655.0, pos_y=258.4999999999992),\n",
       " Row(placa='BRA0K12', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=218.45000000000005),\n",
       " Row(placa='ECU8G90', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=146.25),\n",
       " Row(placa='URU6M78', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=100.30000000000001),\n",
       " Row(placa='BOL3R45', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=780.0),\n",
       " Row(placa='GUY7J89', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=655.0, pos_y=720.15),\n",
       " Row(placa='ECU2U34', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=96.85),\n",
       " Row(placa='URU8C90', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=170.60000000000002),\n",
       " Row(placa='BOL9D01', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=835.0, pos_y=711.0),\n",
       " Row(placa='PER5V67', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=784.0),\n",
       " Row(placa='CHI6S78', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=835.0, pos_y=357.5),\n",
       " Row(placa='SUR0U12', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=385.0, pos_y=91.5),\n",
       " Row(placa='CHI8Q90', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=821.75),\n",
       " Row(placa='BRA6W78', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=748.5),\n",
       " Row(placa='ARG7Z89', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=745.0, pos_y=774.0),\n",
       " Row(placa='PAR1D23', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=103.10000000000001),\n",
       " Row(placa='BOL7F89', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=475.0, pos_y=217.25000000000006),\n",
       " Row(placa='PAR5Z67', rodovia='BR-116', tempo_da_simulacao=142.0, pos_x=655.0, pos_y=403.5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3fdcb69-e1a0-4b9b-a471-ab26947be0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----+------------------+\n",
      "|  placa|rodovia|tempo_da_simulacao|pos_x|             pos_y|\n",
      "+-------+-------+------------------+-----+------------------+\n",
      "|COL1R23| BR-116|             142.0|655.0|             868.0|\n",
      "|CHI0G12| BR-116|             142.0|385.0|            198.05|\n",
      "|CHI2E34| BR-116|             142.0|745.0|            774.15|\n",
      "|URU2Y34| BR-116|             142.0|655.0| 258.4999999999992|\n",
      "|BRA0K12| BR-116|             142.0|475.0|218.45000000000005|\n",
      "|ECU8G90| BR-116|             142.0|475.0|            146.25|\n",
      "|URU6M78| BR-116|             142.0|475.0|100.30000000000001|\n",
      "|BOL3R45| BR-116|             142.0|745.0|             780.0|\n",
      "|GUY7J89| BR-116|             142.0|655.0|            720.15|\n",
      "|ECU2U34| BR-116|             142.0|475.0|             96.85|\n",
      "|URU8C90| BR-116|             142.0|475.0|170.60000000000002|\n",
      "|BOL9D01| BR-116|             142.0|835.0|             711.0|\n",
      "|PER5V67| BR-116|             142.0|745.0|             784.0|\n",
      "|CHI6S78| BR-116|             142.0|835.0|             357.5|\n",
      "|SUR0U12| BR-116|             142.0|385.0|              91.5|\n",
      "|CHI8Q90| BR-116|             142.0|745.0|            821.75|\n",
      "|BRA6W78| BR-116|             142.0|745.0|             748.5|\n",
      "|ARG7Z89| BR-116|             142.0|745.0|             774.0|\n",
      "|PAR1D23| BR-116|             142.0|475.0|103.10000000000001|\n",
      "|BOL7F89| BR-116|             142.0|475.0|217.25000000000006|\n",
      "+-------+-------+------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = ss.createDataFrame(r)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5598ccb7-819d-48c2-b658-c73efc8f8713",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can not infer schema from empty dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM simulacao WHERE tempo_da_simulacao = 143 ALLOW FILTERING;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[0;32m----> 3\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df2\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1276\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m   1275\u001b[0m     )\n\u001b[0;32m-> 1276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1318\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1316\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1318\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:962\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    959\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 962\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[1;32m    964\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:832\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03mInfer schema from list of Row, dict, or tuple.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m:class:`pyspark.sql.types.StructType`\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan not infer schema from empty dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    833\u001b[0m infer_dict_as_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39minferDictAsStruct()\n\u001b[1;32m    834\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n",
      "\u001b[0;31mValueError\u001b[0m: can not infer schema from empty dataset"
     ]
    }
   ],
   "source": [
    "result = session.execute(\"SELECT * FROM simulacao WHERE tempo_da_simulacao = 143 ALLOW FILTERING;\")\n",
    "r = list(result)\n",
    "df2 = ss.createDataFrame(r)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcc112-8579-44f7-97c4-7ae5ea61b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.execute(\"SELECT * FROM simulacao WHERE tempo_da_simulacao = 144 ALLOW FILTERING;\")\n",
    "r = list(result)\n",
    "df25 = ss.createDataFrame(r)\n",
    "df25.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8bf4a-8358-4fec-acdd-8a8922b052aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = ss.createDataFrame([], \"placa: string, posicao: int, linha: int, rodovia: string, tempo_da_simulacao: int, velocidade: double, aceleracao: double, posicao_prevista: double, acima_vel: boolean, aplicaMulta: boolean, tempo_em_curso: int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502d2f2-4070-4fa7-ba5a-67d28e17f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = json.load(open('./mock/parametros.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455de12-32b8-47f1-b1c2-3fd40ceaa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [[key]+list(params[key].values()) for key in params.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67878d-5e54-4270-9a17-f43f9a25464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ss.createDataFrame(p, [\"Rodovia\"]+list(params[list(params.keys())[0]].keys()))\n",
    "\n",
    "p.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa2913-2467-4829-ae7e-55d551f38ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cadb1-49c0-415f-b98d-048645ca1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 30\n",
    "vel_media = 0\n",
    "n_vel_media = 0\n",
    "\n",
    "tempo_medio = 0\n",
    "n_tempo_medio = 0\n",
    "\n",
    "def atualiza_media(media_atual, tamanho_atual, media_add, tamanho_add):\n",
    "    if media_add == None:\n",
    "        return media_atual\n",
    "    if tamanho_atual == 0:\n",
    "        return media_add\n",
    "    tamanho_total = tamanho_atual + tamanho_add\n",
    "    return (media_atual/tamanho_total)*tamanho_atual + (media_add/tamanho_total)*tamanho_add\n",
    "\n",
    "def processa_velocidade_media(batch):\n",
    "    global vel_media, n_vel_media\n",
    "    batch = batch.na.fill(0, subset=['velocidade'])\n",
    "    vel_media_batch = batch.agg(F.mean('velocidade')).collect()[0][0]\n",
    "    length_batch = batch.select(F.count('velocidade')).collect()[0][0]\n",
    "    n_vel_media += length_batch\n",
    "    vel_media = atualiza_media(vel_media, n_vel_media, vel_media_batch, length_batch)\n",
    "    pass\n",
    "\n",
    "def processa_tempo_cruzamento(batch):\n",
    "    global n_tempo_medio, tempo_medio\n",
    "    batch = batch.filter(col(\"tempo_em_curso\") != 0)\n",
    "    tempo_medio_batch = batch.agg(F.mean('tempo_em_curso')).collect()[0][0]\n",
    "    length_batch = batch.select(F.count('tempo_em_curso')).collect()[0][0]\n",
    "    n_tempo_medio += length_batch\n",
    "    tempo_medio = atualiza_media(tempo_medio, n_tempo_medio, tempo_medio_batch, length_batch)\n",
    "    pass\n",
    "\n",
    "def processa_carro(DadosNovos, DadosCarros, colision_tolerance, colision_tolerance_quad, Parametros):\n",
    "    DadosCarros = DadosCarros.drop('aplicaMulta')\n",
    "\n",
    "    # Renomeia coluna do dado novo\n",
    "    DadosNovos = DadosNovos.select(F.col('pos_y').alias('posicao_nova'), F.col('rodovia').alias('rodovia_nova'),\n",
    "                                   F.col('pos_x').alias('linha_nova'),\n",
    "                                   F.col('tempo_da_simulacao').alias('tempo_da_simulacao_novo'),F.col('placa'))\n",
    "    \n",
    "    data_joined = DadosCarros.join(DadosNovos, on=\"placa\", how='right')\n",
    "    \n",
    "    CarrosSumidos = DadosCarros.join(DadosNovos, on=\"placa\", how='left_anti')\n",
    "    processa_tempo_cruzamento(CarrosSumidos)\n",
    "    data_joined = data_joined.withColumn(\"tempo_inicio\", when(col(\"tempo_da_simulacao\").isNull(), col(\"tempo_da_simulacao_novo\")).otherwise(col(\"tempo_da_simulacao\")))\n",
    "    data_joined = data_joined.withColumn(\"tempo_em_curso\", col(\"tempo_da_simulacao_novo\") - col(\"tempo_inicio\"))\n",
    "    data_joined = data_joined.withColumn(\"rodovia\", coalesce(col(\"rodovia_nova\"), col(\"rodovia\")))\n",
    "    data_joined = data_joined.withColumn(\"linha\", coalesce(col(\"linha_nova\"), col(\"linha\")))\n",
    "    data_joined = data_joined.drop(\"rodovia_nova\", \"linha_nova\")\n",
    "    \n",
    "    data_joined = data_joined.withColumn(\"diferenca_de_posicao\", col(\"posicao_nova\") - col(\"posicao\"))\n",
    "    \n",
    "    data_joined = data_joined.withColumn(\"diferenca_de_horario\", (col(\"tempo_da_simulacao_novo\") - col(\"tempo_da_simulacao\"))*fps)\n",
    "\n",
    "    data_joined = data_joined.withColumnRenamed(\"velocidade\", \"velocidade_antiga\")\n",
    "\n",
    "    data_joined = data_joined.withColumn(\"velocidade\", col(\"diferenca_de_posicao\") / col(\"diferenca_de_horario\"))\n",
    "    processa_velocidade_media(data_joined)\n",
    "    \n",
    "    data_joined = data_joined.withColumn(\"diferenca_de_velocidade\", col(\"velocidade\") - col(\"velocidade_antiga\"))\n",
    "\n",
    "    data_joined = data_joined.withColumn(\"aceleracao\", col(\"diferenca_de_velocidade\") / col(\"diferenca_de_horario\"))\n",
    "\n",
    "    data_joined = data_joined.drop(\"velocidade_antiga\", \"posicao\", \"tempo_da_simulacao\",\n",
    "                     \"diferenca_de_posicao\", \"diferenca_de_horario\",\n",
    "                     \"diferenca_de_velocidade\")\n",
    "\n",
    "    data_joined = data_joined.withColumnRenamed(\"posicao_nova\", \"posicao\")\n",
    "\n",
    "    data_joined = data_joined.withColumnRenamed(\"tempo_da_simulacao_novo\", \"tempo_da_simulacao\")\n",
    "\n",
    "    data_joined = data_joined.withColumn(\"posicao_prevista\", col(\"posicao\")\\\n",
    "                           + col(\"velocidade\")*colision_tolerance\\\n",
    "                           + col(\"aceleracao\")*colision_tolerance_quad)\n",
    "\n",
    "    Velocidades_Maximas = Parametros.select(F.col('rodovia'), F.col(\"VelocidadeMaxima\"))\n",
    "    data_joined = data_joined.join(Velocidades_Maximas, on=\"rodovia\", how=\"left\")\n",
    "\n",
    "    acima_vel_df = data_joined.select(F.col('placa'), F.col('acima_vel').alias('acima_vel_antigo'))\n",
    "    data_joined = data_joined.withColumn(\"acima_vel\", F.when(F.abs(data_joined[\"velocidade\"]) > F.abs(fps/data_joined[\"VelocidadeMaxima\"]), 1).otherwise(0))\n",
    "\n",
    "    acima_vel_df = acima_vel_df.join(data_joined.select(F.col('placa'), F.col('acima_vel').alias('acima_vel_novo')), on='placa', how=\"left\")\n",
    "    acima_vel_df = acima_vel_df.withColumn(\"aplicaMulta\", (F.col('acima_vel_antigo')==0) &  (F.col('acima_vel_novo')==1) )\n",
    "\n",
    "    data_joined = data_joined.join(acima_vel_df.select(F.col('placa'), F.col('aplicaMulta')), on='placa', how='left')\n",
    "\n",
    "    data_joined = data_joined.drop(\"VelocidadeMaxima\")\n",
    "    return data_joined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d8999-3b56-4278-b474-3fd0f209050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c36cec-dce4-4800-a073-59778241b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = processa_carro(df, df_empty, 1, 0.5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494187c2-026f-4266-bc67-f6174c77fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = processa_carro(df2, df3, 1, 0.5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec68e6-fb26-4551-bcc5-fa3062fc4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = processa_carro(df25, df3, 1, 0.5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257280c-9082-47ef-8022-2aec353daf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb11ff-d65f-4466-b934-4d4e7d507c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f9eca-c6c9-4acf-ae3f-8b453176aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"rodovia\", \"linha\").orderBy('posicao')\n",
    "\n",
    "# Use lag function with the window specification\n",
    "lag_column = col(\"velocidade\")*(col(\"posicao_prevista\") - lag(col(\"posicao_prevista\")).over(window_spec))\n",
    "\n",
    "# Add the lag column to the DataFrame\n",
    "result = df4.withColumn(\"lag_value\", when(lag_column < 0, 1).otherwise(0))\n",
    "\n",
    "# Show the result\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49973c54-8e60-498c-961a-2a38c300d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Alice\", 25),\n",
    "        (\"Bob\", 30),\n",
    "        (\"Charlie\", 27),\n",
    "        (\"Diana\", 35),\n",
    "        (\"Eva\", 32)]\n",
    "\n",
    "df10.withColumn(\"RowNumber\", F.row_number().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98042b2f-891b-4d49-8ff6-ad692c51e46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15d84c-be7e-48ca-944d-f4281f480ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d741f-3a16-4e45-babe-8b62024bce96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
